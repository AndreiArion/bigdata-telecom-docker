{
  "metadata" : {
    "config" : {
      "dependencies" : {
        "scala" : [
          "com.datastax.spark:spark-cassandra-connector-driver_2.12:3.1.0"
        ]
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.executor.userClasspathFirst" : "true",
        "spark.jars.packages" : "com.datastax.spark:spark-cassandra-connector-driver_2.12:3.1.0",
        "spark.driver.userClasspathFirst" : "true",
        "spark.master" : "local[*]",
        "spark.sql.extensions" : "com.datastax.spark.connector.CassandraSparkExtensions",
        "spark_submit_args" : "--packages com.datastax.spark:spark-cassandra-connector-driver_2.12:3.1.0",
        "spark.cassandra.connection.host" : "cassandra-1"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "code",
      "execution_count" : 28,
      "metadata" : {
        "language" : "viz"
      },
      "language" : "viz",
      "source" : [
        "{\"type\":\"mime\",\"mimeType\":\"text/html\",\"value\":\"spark\"}"
      ],
      "outputs" : [
        {
          "data" : {
            "text/html" : [
              "<div class=\"object-display spark-ui\">\n",
              "  <div>Spark Version 3.3.1</div>\n",
              "  <div><span class=\"field-name\">Spark UI</span><a href=\"http://127.0.0.1:4040\" class=\"link\" target=\"_blank\">http://127.0.0.1:4040</a></div>\n",
              "</div>\n",
              "<details class=\"object-display\" open>\n",
              "  <summary class=\"object-summary\"><span class=\"summary-content\"><span>Configuration</span></span></summary>\n",
              "  <ul class=\"object-fields\">\n",
              "          \n",
              "<li>\n",
              "<span class=\"field-name\">spark.sql.warehouse.dir</span><span class=\"string\">file:/opt/polynote/spark-warehouse</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.executor.extraJavaOptions</span><span class=\"string\">-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.driver.host</span><span class=\"string\">127.0.0.1</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.driver.port</span><span class=\"string\">33331</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.executor.userClasspathFirst</span><span class=\"string\">true</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.executorEnv.PYTHONPATH</span><span class=\"string\">./pyspark.zip:./py4j-0.10.9.5-src.zip</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.repl.class.uri</span><span class=\"string\">spark://127.0.0.1:33331/classes</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.jars</span><span class=\"string\">/opt/polynote/deps/2.12/polynote-spark-runtime-assembly-0.4.10.jar,/opt/polynote/deps/2.12/polynote-runtime-assembly-0.4.10.jar,/opt/polynote/deps/2.12/polynote-runtime-assembly-0.4.10.jar,https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector-driver_2.12/3.1.0/spark-cassandra-connector-driver_2.12-3.1.0.jar,https://repo1.maven.org/maven2/com/datastax/oss/java-driver-core-shaded/4.12.0/java-driver-core-shaded-4.12.0.jar,https://repo1.maven.org/maven2/com/datastax/oss/java-driver-mapper-runtime/4.12.0/java-driver-mapper-runtime-4.12.0.jar,https://repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.10/commons-lang3-3.10.jar,https://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar,https://repo1.maven.org/maven2/com/datastax/oss/native-protocol/1.5.0/native-protocol-1.5.0.jar,https://repo1.maven.org/maven2/com/datastax/oss/java-driver-shaded-guava/25.1-jre-graal-sub-1/java-driver-shaded-guava-25.1-jre-graal-sub-1.jar,https://repo1.maven.org/maven2/com/typesafe/config/1.4.1/config-1.4.1.jar,https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar,https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/4.1.18/metrics-core-4.1.18.jar,https://repo1.maven.org/maven2/org/hdrhistogram/HdrHistogram/2.1.12/HdrHistogram-2.1.12.jar,https://repo1.maven.org/maven2/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar,https://repo1.maven.org/maven2/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar,https://repo1.maven.org/maven2/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar,https://repo1.maven.org/maven2/com/datastax/oss/java-driver-query-builder/4.12.0/java-driver-query-builder-4.12.0.jar,https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.repl.class.outputDir</span><span class=\"string\">/tmp/spark-12bda6d5-c083-479e-9046-547a54506502/repl-f4419225-b377-4b75-9c5f-dfbeb23b1d6f</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.app.name</span><span class=\"string\">Polynote 0.4.10: TP Spark2 Dataframe Datasets.ipynb</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.submit.pyFiles</span><span class=\"string\"></span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.app.submitTime</span><span class=\"string\">1669876294666</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.jars.packages</span><span class=\"string\">com.datastax.spark:spark-cassandra-connector-driver_2.12:3.1.0</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.app.startTime</span><span class=\"string\">1669876298659</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.executor.id</span><span class=\"string\">driver</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.driver.extraJavaOptions</span><span class=\"string\">-Dlog4j.configuration=log4j.properties -Djava.library.path=/usr/local/lib/python3.8/dist-packages/jep</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.driver.userClasspathFirst</span><span class=\"string\">true</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.app.initial.jar.urls</span><span class=\"string\">https://repo1.maven.org/maven2/com/datastax/oss/java-driver-mapper-runtime/4.12.0/java-driver-mapper-runtime-4.12.0.jar,https://repo1.maven.org/maven2/org/hdrhistogram/HdrHistogram/2.1.12/HdrHistogram-2.1.12.jar,spark://127.0.0.1:33331/jars/polynote-spark-runtime-assembly-0.4.10.jar,https://repo1.maven.org/maven2/com/datastax/oss/native-protocol/1.5.0/native-protocol-1.5.0.jar,https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector-driver_2.12/3.1.0/spark-cassandra-connector-driver_2.12-3.1.0.jar,https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar,https://repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.10/commons-lang3-3.10.jar,spark://127.0.0.1:33331/jars/polynote-runtime-assembly-0.4.10.jar,https://repo1.maven.org/maven2/com/datastax/oss/java-driver-core-shaded/4.12.0/java-driver-core-shaded-4.12.0.jar,https://repo1.maven.org/maven2/com/datastax/oss/java-driver-query-builder/4.12.0/java-driver-query-builder-4.12.0.jar,https://repo1.maven.org/maven2/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar,https://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar,https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/4.1.18/metrics-core-4.1.18.jar,https://repo1.maven.org/maven2/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar,https://repo1.maven.org/maven2/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar,https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar,https://repo1.maven.org/maven2/com/datastax/oss/java-driver-shaded-guava/25.1-jre-graal-sub-1/java-driver-shaded-guava-25.1-jre-graal-sub-1.jar,https://repo1.maven.org/maven2/com/typesafe/config/1.4.1/config-1.4.1.jar</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.submit.deployMode</span><span class=\"string\">client</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.master</span><span class=\"string\">local[*]</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.driver.extraClassPath</span><span class=\"string\">/opt/polynote/deps/2.12/scala-library-2.12.12.jar:/opt/polynote/deps/2.12/polynote-spark-assembly-0.4.10.jar:/opt/polynote/deps/2.12/polynote-spark-runtime-assembly-0.4.10.jar:/opt/polynote/deps/2.12/scala-compiler-2.12.12.jar:/opt/polynote/deps/2.12/polynote-kernel-assembly-0.4.10.jar:/opt/polynote/deps/2.12/scala-reflect-2.12.12.jar:/opt/polynote/deps/2.12/scala-xml_2.12-1.2.0.jar:/opt/polynote/deps/2.12/polynote-runtime-assembly-0.4.10.jar:/opt/polynote/deps/2.12/polynote-server-assembly-0.4.10.jar:/opt/polynote/deps/2.12/scala-collection-compat_2.12-2.1.1.jar</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.home</span><span class=\"string\">/opt/spark</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.sql.catalogImplementation</span><span class=\"string\">hive</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.repl.local.jars</span><span class=\"string\">file:///opt/polynote/deps/2.12/polynote-spark-runtime-assembly-0.4.10.jar,file:///opt/polynote/deps/2.12/polynote-runtime-assembly-0.4.10.jar,file:///home/polly/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.1.0.jar,file:///home/polly/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.12.0.jar,file:///home/polly/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.12.0.jar,file:///home/polly/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar,file:///home/polly/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar,file:///home/polly/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar,file:///home/polly/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar,file:///home/polly/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar,file:///home/polly/.ivy2/jars/com.typesafe_config-1.4.1.jar,file:///home/polly/.ivy2/jars/org.slf4j_slf4j-api-1.7.26.jar,file:///home/polly/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar,file:///home/polly/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar,file:///home/polly/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar,file:///home/polly/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar,file:///home/polly/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar,file:///home/polly/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar,file:///home/polly/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.12.0.jar</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.sql.extensions</span><span class=\"string\">com.datastax.spark.connector.CassandraSparkExtensions</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark_submit_args</span><span class=\"string\">--packages com.datastax.spark:spark-cassandra-connector-driver_2.12:3.1.0</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.app.id</span><span class=\"string\">local-1669876299192</span>\n",
              "</li>\n",
              "            \n",
              "<li>\n",
              "<span class=\"field-name\">spark.cassandra.connection.host</span><span class=\"string\">cassandra-1</span>\n",
              "</li>\n",
              "            \n",
              "</ul></details>\n",
              "          \n",
              "           "
            ]
          },
          "output_type" : "display_data"
        }
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "## Excercices scala (dans PolyNotes)\n",
        "\n",
        "\n",
        "*Architecture: https://github.com/AndreiArion/bigdata-telecom-docker/blob/main/architecture.png*\n",
        "\n",
        "\n",
        "*Dans votre environnement  vous avez les URLs suivants:*\n",
        "\n",
        "\n",
        "* \n",
        "  Spark Driver (polynote) : [http://localhost:4043](http://localhost:4043/)\n",
        "  \n",
        "  \n",
        "  \n",
        "* \n",
        "  Spark Master : [http://localhost:9090/](http://localhost:9090/)\n",
        "  \n",
        "  \n",
        "  \n",
        "* \n",
        "  Spark Worker 1: [http://localhost:9091/](http://localhost:9091/)\n",
        "  \n",
        "  \n",
        "  \n",
        "* \n",
        "  Spark Worker 2: [http://localhost:9092/](http://localhost:9092/)\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "*Vous pouvez commencer par les exercices Scala ([http://andreiarion.github.io/TP4_TPSpark_RDD.html#excercices-scala](http://andreiarion.github.io/TP4_TPSpark_RDD.html#excercices-scala) )*<br>\n",
        "\n",
        "*Documentation: **[https://spark.apache.org/docs/latest/rdd-programming-guide.html](https://spark.apache.org/docs/latest/rdd-programming-guide.html)*\n",
        "\n",
        "*<br>*\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 1,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "<pre style=\"background-color:#131314;color:#ebebeb;font-family:'Fira Code',monospace;font-size:13.5pt;\"><h2><code>Intro\n",
        "Pour les exercices suivant on va utiliser une base de donnees publique du gouvernement qui contient des donnees sur les accidents de la route (https://www.data.gouv.fr/fr/datasets/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2021 \n",
        "\n",
        "Nous allons utiliser des dataframes et datasets pour manipuler ces donnees.\n",
        "\n",
        "\n",
        "Description des donnees\n",
        "Pour chaque accident corporel (soit un accident survenu sur une voie ouverte à la circulation publique, impliquant au moins un véhicule et ayant fait au moins une victime ayant nécessité des soins), des saisies d’information décrivant l’accident sont effectuées par l’unité des forces de l’ordre (police, gendarmerie, etc.) qui est intervenue sur le lieu de l’accident.\n",
        "\n",
        "Ces saisies sont rassemblées dans une fiche intitulée bulletin d’analyse des accidents corporels (BAAC). Cela comprend des informations de localisation de l’accident, telles que renseignées ainsi que des informations concernant les caractéristiques de l’accident et son lieu, les véhicules impliqués et leurs victimes.\n",
        "\n",
        "Les bases de données de 2005 à 2021 sont désormais annuelles et composées de 4 fichiers (Caractéristiques – Lieux – Véhicules – Usagers ) au format csv.\n",
        "\n",
        "La description des differents fichiers se trouve ici: https://www.data.gouv.fr/fr/datasets/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2021/Documentation\n",
        "\n",
        "Documentation dataframes: http://spark.apache.org/docs/latest/sql-programming-guide.html#creating-dataframes Documentation API scala: http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\n",
        "\n",
        "Dans les exercices suivants remplaceez les TODO par le code necessaire</code><br></h2></pre>"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669850101249,
          "endTs" : 1669850101638
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import org.apache.spark.sql.SparkSession\n",
        "import org.apache.spark.SparkConf\n",
        "def TODO = ??? // ceci est juste un marquer d'une valeur que vous devez remplacer dans les lignes qui suivent\n",
        "// on cree une session Spark avec un nom particulier pour la retrouver plus facilement dans le SparkUI\n",
        "val mySession = SparkSession\n",
        "  .builder()\n",
        "  .config(new SparkConf()\n",
        "             .setAppName(\"TODO\"))//rajouter comme parametre le nom de votre application\n",
        "  .getOrCreate()"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 3,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669850828093,
          "endTs" : 1669850828981
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val path = \"/opt/spark-data\"\n",
        "// Lecture des donnes dans des DataFrames en utilisant la premier ligne du fichier comme nom des colonnes\n",
        "val lieux /*:DataFrame*/ = mySession.read\n",
        "                                    .option(\"header\",\"true\")\n",
        "                                    .option(\"sep\",\";\")\n",
        "                                    .option(\"quoteAll\",\"true\")\n",
        "                                    .format(\"com.databricks.spark.csv\")\n",
        "                                    .load(path + \"/lieux-2021.csv\")\n",
        "                                    .cache\n",
        "val caracteristiques = mySession.read.option(\"header\",\"true\")\n",
        "                                    .option(\"sep\",\";\")\n",
        "                                    .option(\"quoteAll\",\"true\")\n",
        "                                    .format(\"com.databricks.spark.csv\")\n",
        "                                    .load(path + \"/carcteristiques-2021.csv\")\n",
        "                                    .cache\n",
        "val usagers = mySession.read.option(\"header\",\"true\")\n",
        "                                    .option(\"sep\",\";\")\n",
        "                                    .option(\"quoteAll\",\"true\")\n",
        "                                    .format(\"com.databricks.spark.csv\")\n",
        "                                    .load(path + \"/usagers-2021.csv\")\n",
        "                                    .cache\n",
        "//val vehicules = TODO\n",
        "val vehicules = mySession.read.option(\"header\",\"true\")\n",
        "                                    .option(\"sep\",\";\")\n",
        "                                    .option(\"quoteAll\",\"true\")\n",
        "                                    .format(\"com.databricks.spark.csv\")\n",
        "                                    .load(path + \"/vehicules-2021.csv\")\n",
        "                                    .cache\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 4,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669850830378,
          "endTs" : 1669850830500
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Un DataFrame est un DataSet[Row] ou par default chaque ligne est une \"String\"\n",
        "lieux.printSchema\n",
        "caracteristiques.printSchema\n",
        "usagers.printSchema\n",
        "vehicules.printSchema"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "root\n",
            " |-- Num_Acc: string (nullable = true)\n",
            " |-- catr: string (nullable = true)\n",
            " |-- voie: string (nullable = true)\n",
            " |-- v1: string (nullable = true)\n",
            " |-- v2: string (nullable = true)\n",
            " |-- circ: string (nullable = true)\n",
            " |-- nbv: string (nullable = true)\n",
            " |-- vosp: string (nullable = true)\n",
            " |-- prof: string (nullable = true)\n",
            " |-- pr: string (nullable = true)\n",
            " |-- pr1: string (nullable = true)\n",
            " |-- plan: string (nullable = true)\n",
            " |-- lartpc: string (nullable = true)\n",
            " |-- larrout: string (nullable = true)\n",
            " |-- surf: string (nullable = true)\n",
            " |-- infra: string (nullable = true)\n",
            " |-- situ: string (nullable = true)\n",
            " |-- vma: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- Num_Acc: string (nullable = true)\n",
            " |-- jour: string (nullable = true)\n",
            " |-- mois: string (nullable = true)\n",
            " |-- an: string (nullable = true)\n",
            " |-- hrmn: string (nullable = true)\n",
            " |-- lum: string (nullable = true)\n",
            " |-- dep: string (nullable = true)\n",
            " |-- com: string (nullable = true)\n",
            " |-- agg: string (nullable = true)\n",
            " |-- int: string (nullable = true)\n",
            " |-- atm: string (nullable = true)\n",
            " |-- col: string (nullable = true)\n",
            " |-- adr: string (nullable = true)\n",
            " |-- lat: string (nullable = true)\n",
            " |-- long: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- Num_Acc: string (nullable = true)\n",
            " |-- id_vehicule: string (nullable = true)\n",
            " |-- num_veh: string (nullable = true)\n",
            " |-- place: string (nullable = true)\n",
            " |-- catu: string (nullable = true)\n",
            " |-- grav: string (nullable = true)\n",
            " |-- sexe: string (nullable = true)\n",
            " |-- an_nais: string (nullable = true)\n",
            " |-- trajet: string (nullable = true)\n",
            " |-- secu1: string (nullable = true)\n",
            " |-- secu2: string (nullable = true)\n",
            " |-- secu3: string (nullable = true)\n",
            " |-- locp: string (nullable = true)\n",
            " |-- actp: string (nullable = true)\n",
            " |-- etatp: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- Num_Acc: string (nullable = true)\n",
            " |-- id_vehicule: string (nullable = true)\n",
            " |-- num_veh: string (nullable = true)\n",
            " |-- senc: string (nullable = true)\n",
            " |-- catv: string (nullable = true)\n",
            " |-- obs: string (nullable = true)\n",
            " |-- obsm: string (nullable = true)\n",
            " |-- choc: string (nullable = true)\n",
            " |-- manv: string (nullable = true)\n",
            " |-- motor: string (nullable = true)\n",
            " |-- occutc: string (nullable = true)\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 5,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669850924932,
          "endTs" : 1669850925117
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// on peut utiliser la methode show pour afficher le contenu d'un DataFrame\n",
        "//TODO // affiche 4 lignes du dataframe usagers\n",
        "usagers.show(4)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+------------+-----------+-------+-----+----+----+----+-------+------+-----+-----+-----+----+----+-----+\n",
            "|     Num_Acc|id_vehicule|num_veh|place|catu|grav|sexe|an_nais|trajet|secu1|secu2|secu3|locp|actp|etatp|\n",
            "+------------+-----------+-------+-----+----+----+----+-------+------+-----+-----+-----+----+----+-----+\n",
            "|202100000001|    201 764|    B01|    1|   1|   3|   1|   2000|     1|    0|    9|   -1|   0|   0|   -1|\n",
            "|202100000001|    201 765|    A01|    1|   1|   1|   1|   1978|     1|    1|   -1|   -1|   0|   0|   -1|\n",
            "|202100000002|    201 762|    A01|    1|   1|   4|   1|   1983|     0|    1|   -1|   -1|   0|   0|   -1|\n",
            "|202100000002|    201 763|    B01|    1|   1|   3|   1|   1993|     0|    1|   -1|   -1|   0|   0|   -1|\n",
            "+------------+-----------+-------+-----+----+----+----+-------+------+-----+-----+-----+----+----+-----+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 6,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669850992370,
          "endTs" : 1669850993688
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "print {\n",
        "  s\"Le jeu de donnees contiens ${lieux.count} accidents qui ont implique ${vehicules.count} vehicules, ${usagers.count} personnes. Le nombre des caracteristiques des accidents: ${caracteristiques.count}\"\n",
        "}\n"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "Le jeu de donnees contiens 56518 accidents qui ont implique 97315 vehicules, 129153 personnes. Le nombre des caracteristiques des accidents: 56518"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 7,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669851657314,
          "endTs" : 1669851657825
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "//Nombre victimes selons la gravite\n",
        "val victimes = usagers.filter(\"grav>0\").groupBy(\"grav\").count\n",
        "victimes.printSchema\n",
        "victimes.show // pour afficher le contenu\n"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "root\n",
            " |-- grav: string (nullable = true)\n",
            " |-- count: long (nullable = false)\n",
            "\n",
            "+----+-----+\n",
            "|grav|count|\n",
            "+----+-----+\n",
            "|   3|19085|\n",
            "|   1|55108|\n",
            "|   4|51681|\n",
            "|   2| 3219|\n",
            "+----+-----+\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 8,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669851676649,
          "endTs" : 1669851676985
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Hmm, les valeurs numeriques ne sont pas trop comprehensible, nous pouvons les decoder en utilisant \n",
        "victimes.map{\n",
        "  row => {\n",
        "    val mapping = Map(\n",
        "      \"1\" -> \"Indemne\",\n",
        "      \"2\" -> \"Tué\",\n",
        "      \"3\" -> \"Blessé hospitalisé\",\n",
        "      \"4\" -> \"Blessé léger\"\n",
        "    )\n",
        "    mapping(row.getAs[String](\"grav\")) +\" : \"+ row.getAs[String](\"count\")\n",
        "  }\n",
        "}.show(10, false)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+--------------------------+\n",
            "|value                     |\n",
            "+--------------------------+\n",
            "|Blessé hospitalisé : 19085|\n",
            "|Indemne : 55108           |\n",
            "|Blessé léger : 51681      |\n",
            "|Tué : 3219                |\n",
            "+--------------------------+\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 9,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "1. Quel est le nombre des blesses de la route en 2021?\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 10,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669851747309,
          "endTs" : 1669851747612
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "usagers.filter($\"grav\" === 3 ).count\n"
      ],
      "outputs" : [
        {
          "execution_count" : 10,
          "data" : {
            "text/plain" : [
              "19085"
            ]
          },
          "metadata" : {
            "name" : "Out",
            "type" : "Long"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 11,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "2. Quelle est la repartition des victimes par age ?\n",
        "Quel est le type de la colonne \"an_nais\" du dataframe \"_usagers\" ? Comment peut-on calculer la date de naissance?"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 12,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669851842664,
          "endTs" : 1669851842830
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import org.apache.spark.sql.types._\n",
        "// d'abord on doit creer une nouvelle colonne an_nais_int = pour convertir la colonne an_nais en entier\n",
        "val usagers1 = usagers.withColumn(\"an_nais_int\", col(\"an_nais\").cast(IntegerType))"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 13,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669851893931,
          "endTs" : 1669851894231
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// puis on defini une User Defined Function qui calcule l'age a partir de la date de naissance\n",
        "val computeAge = udf {(an_nais: Int) =>  2021 - an_nais}\n",
        "//et on rajoute une nouvelle colonne qui sera peuplee avec le resultat de l'application de l'udf computeAge sur la colonne \"an_nais\"\n",
        "val usagersAge = usagers1.withColumn(\"age\", computeAge($\"an_nais\") )\n",
        "usagersAge.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+------------+-----------+-------+-----+----+----+----+-------+------+-----+-----+-----+----+----+-----+-----------+----+\n",
            "|     Num_Acc|id_vehicule|num_veh|place|catu|grav|sexe|an_nais|trajet|secu1|secu2|secu3|locp|actp|etatp|an_nais_int| age|\n",
            "+------------+-----------+-------+-----+----+----+----+-------+------+-----+-----+-----+----+----+-----+-----------+----+\n",
            "|202100000001|    201 764|    B01|    1|   1|   3|   1|   2000|     1|    0|    9|   -1|   0|   0|   -1|       2000|  21|\n",
            "|202100000001|    201 765|    A01|    1|   1|   1|   1|   1978|     1|    1|   -1|   -1|   0|   0|   -1|       1978|  43|\n",
            "|202100000002|    201 762|    A01|    1|   1|   4|   1|   1983|     0|    1|   -1|   -1|   0|   0|   -1|       1983|  38|\n",
            "|202100000002|    201 763|    B01|    1|   1|   3|   1|   1993|     0|    1|   -1|   -1|   0|   0|   -1|       1993|  28|\n",
            "|202100000003|    201 761|    A01|    1|   1|   1|   1|   1995|     1|    1|    0|   -1|   0|   0|   -1|       1995|  26|\n",
            "|202100000003|    201 761|    A01|   10|   3|   3|   2|   1959|     4|    0|   -1|   -1|   3|   3|    1|       1959|  62|\n",
            "|202100000004|    201 758|    A01|    1|   1|   1|   1|   2000|    -1|   -1|    0|   -1|  -1|  -1|   -1|       2000|  21|\n",
            "|202100000004|    201 759|    D01|    1|   1|   2|   2|   2014|     5|    0|   -1|   -1|  -1|  -1|   -1|       2014|   7|\n",
            "|202100000005|    201 754|    A01|    1|   1|   4|   2|   1997|     1|    1|   -1|   -1|  -1|  -1|   -1|       1997|  24|\n",
            "|202100000005|    201 755|    Z01|    1|   1|  -1|  -1|   null|    -1|    8|   -1|   -1|  -1|  -1|   -1|       null|null|\n",
            "|202100000006|    201 752|    B01|    1|   1|   4|   1|   2009|     2|    0|   -1|   -1|   0|   0|   -1|       2009|  12|\n",
            "|202100000006|    201 753|    A01|    1|   1|   1|   1|   1976|     5|    1|   -1|   -1|   0|   0|   -1|       1976|  45|\n",
            "|202100000007|    201 750|    B01|    1|   1|   1|   1|   2001|     5|    1|    5|   -1|  -1|  -1|   -1|       2001|  20|\n",
            "|202100000007|    201 750|    B01|    4|   2|   4|   2|   2002|     0|    1|    0|   -1|  -1|  -1|   -1|       2002|  19|\n",
            "|202100000007|    201 751|    A01|    1|   1|   4|   1|   1991|     0|    1|    5|   -1|  -1|  -1|   -1|       1991|  30|\n",
            "|202100000008|    201 748|    B01|    1|   1|   3|   1|   1972|     5|    2|   -1|   -1|   0|   0|   -1|       1972|  49|\n",
            "|202100000008|    201 748|    B01|    2|   2|   4|   2|   1984|     5|    8|   -1|   -1|   0|   0|   -1|       1984|  37|\n",
            "|202100000008|    201 749|    A01|    1|   1|   1|   1|   1971|     5|    1|   -1|   -1|   0|   0|   -1|       1971|  50|\n",
            "|202100000009|    201 746|    A01|    1|   1|   1|   1|   1981|     1|    1|    0|   -1|  -1|  -1|   -1|       1981|  40|\n",
            "|202100000009|    201 747|    B01|    1|   1|   1|   1|   1935|     5|    1|    0|   -1|  -1|  -1|   -1|       1935|  86|\n",
            "+------------+-----------+-------+-----+----+----+----+-------+------+-----+-----+-----+----+----+-----+-----------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 14,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669852250815,
          "endTs" : 1669852251139
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Afficher la repartition des victimes par age, triee par l'age des victimes\n",
        "usagersAge.filter(\"age is not null\").groupBy(\"age\").count().show(100)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+---+-----+\n",
            "|age|count|\n",
            "+---+-----+\n",
            "| 31| 2617|\n",
            "| 85|  296|\n",
            "| 65|  821|\n",
            "| 53| 1657|\n",
            "| 78|  440|\n",
            "| 34| 2322|\n",
            "| 81|  343|\n",
            "| 28| 2814|\n",
            "| 76|  470|\n",
            "| 27| 2811|\n",
            "| 26| 2941|\n",
            "| 44| 1773|\n",
            "| 12|  623|\n",
            "| 91|  115|\n",
            "| 22| 3792|\n",
            "| 93|   51|\n",
            "| 47| 1750|\n",
            "|  1|  336|\n",
            "| 52| 1593|\n",
            "| 13|  640|\n",
            "| 16| 1712|\n",
            "| 86|  259|\n",
            "|  6|  377|\n",
            "|  3|  414|\n",
            "| 20| 4056|\n",
            "| 40| 1911|\n",
            "| 94|   40|\n",
            "| 57| 1461|\n",
            "| 54| 1556|\n",
            "| 96|   15|\n",
            "| 48| 1805|\n",
            "|  5|  392|\n",
            "| 19| 3750|\n",
            "| 92|   60|\n",
            "| 64|  893|\n",
            "| 41| 2024|\n",
            "| 15| 1228|\n",
            "| 43| 1754|\n",
            "| 37| 2117|\n",
            "| 61| 1163|\n",
            "| 88|  191|\n",
            "| 17| 2064|\n",
            "|  9|  413|\n",
            "| 72|  688|\n",
            "| 35| 2239|\n",
            "| 59| 1336|\n",
            "| 55| 1525|\n",
            "|  4|  377|\n",
            "|  8|  404|\n",
            "| 23| 3449|\n",
            "| 39| 2043|\n",
            "| 49| 1848|\n",
            "|  7|  422|\n",
            "| 84|  291|\n",
            "| 87|  213|\n",
            "| 51| 1709|\n",
            "| 69|  754|\n",
            "| 97|   10|\n",
            "| 63|  976|\n",
            "| 77|  432|\n",
            "| 10|  481|\n",
            "| 50| 1708|\n",
            "| 45| 1689|\n",
            "| 38| 2004|\n",
            "| 82|  332|\n",
            "| 80|  360|\n",
            "| 25| 3117|\n",
            "| 73|  635|\n",
            "| 24| 3174|\n",
            "| 70|  701|\n",
            "| 62| 1047|\n",
            "| 95|   25|\n",
            "| 29| 2692|\n",
            "| 21| 4134|\n",
            "| 32| 2504|\n",
            "| 60| 1344|\n",
            "| 90|  131|\n",
            "| 75|  624|\n",
            "| 56| 1491|\n",
            "| 58| 1372|\n",
            "| 33| 2428|\n",
            "| 11|  497|\n",
            "| 83|  327|\n",
            "| 68|  708|\n",
            "| 71|  707|\n",
            "| 14|  750|\n",
            "| 42| 1786|\n",
            "|  2|  338|\n",
            "| 79|  426|\n",
            "| 30| 2648|\n",
            "| 99|    2|\n",
            "| 66|  805|\n",
            "| 46| 1727|\n",
            "| 67|  799|\n",
            "|  0|  234|\n",
            "| 18| 2695|\n",
            "| 74|  660|\n",
            "| 36| 2230|\n",
            "| 89|  166|\n",
            "|101|    2|\n",
            "+---+-----+\n",
            "only showing top 100 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 15,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "1. Quelles sont les caracteristiques de 3 accidents le plus meurtriers de 2021 (date, nb vehicules, conditions meteo)¶\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 16,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669852341094,
          "endTs" : 1669852343074
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val accidents = usagers\n",
        "    .filter($\"grav\" === 2 ) // on filtre les victimes\n",
        "    .groupBy(\"Num_Acc\") // on groupe sur l'id de l'accident\n",
        "    .count() // on compte le nombre des victimes\n",
        "    .sort(desc(\"count\"))// on trie par le nombre des victimes\n",
        "    .limit(3)// on garde uniquement les 3 accidents les plus meurtirers\n",
        "    .withColumnRenamed(\"count\",\"nb_victimes\")\n",
        "    .join(caracteristiques, usagers(\"Num_acc\")=== caracteristiques(\"Num_Acc\"))// on fait le jointure avec les caracteristiques\n",
        "    .join(lieux, usagers(\"Num_acc\")=== lieux(\"Num_Acc\"))// on fait le jointure avec les lieux\n",
        "    .join(vehicules, usagers(\"Num_Acc\")=== vehicules(\"Num_Acc\")) // on fait la jointure avec les vehicules\n",
        "    .groupBy(caracteristiques(\"an\"),caracteristiques(\"mois\"),caracteristiques(\"jour\"),caracteristiques(\"adr\"),caracteristiques(\"dep\"), caracteristiques(\"atm\"),$\"nb_victimes\") // on groupe sur les colonnes qui nous interessent\n",
        "    .count().withColumnRenamed(\"count\",\"nb_vehicules\") // on compte le nombre des vehicules\n",
        "accidents.show"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+----+----+----+--------------------+---+---+-----------+------------+\n",
            "|  an|mois|jour|                 adr|dep|atm|nb_victimes|nb_vehicules|\n",
            "+----+----+----+--------------------+---+---+-----------+------------+\n",
            "|2021|  05|  10|      Bel Air RN 147| 87|  1|          4|           1|\n",
            "|2021|  08|  18|CHEMIN DES SANGLIERS| 83|  1|          5|           1|\n",
            "|2021|  02|   3|      A36 PK 112.000| 68|  3|          4|           2|\n",
            "+----+----+----+--------------------+---+---+-----------+------------+\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 17,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "Datasets (typer les DataFrames) \n",
        "\n",
        "Dans les excercices precedents on a manipule des DataFrames = ensembles de lignes de chaines de caracteres. Les datasets nous permettent de rajouter de types au colonnes pour les manipuler plus facilement.\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 18,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669852416591,
          "endTs" : 1669852416904
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// On commence par definir une case class qui va definir le types des lignes de notre jeu de donnes\n",
        "case class Caracteristiques(NumAcc: String, latitude: Double, longitude:Double,adr: String, colType: Int)\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 19,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669853136407,
          "endTs" : 1669853136508
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "//On doit transformer chaque ligne (Row) dans un objet Caracteristiques\n",
        "// on defini une fonction de mapping qui prends un objet de type Row et retourne une Caracteristique\n",
        "import org.apache.spark.sql.Row\n",
        "def mapRow(r:Row): Caracteristiques = {\n",
        "  Caracteristiques(\n",
        "    r.getAs[String](\"Num_Acc\"),\n",
        "    r.getAs[String](\"lat\").replace(',','.').toDouble, \n",
        "    r.getAs[String](\"long\").replace(',','.').toDouble, \n",
        "    r.getAs[String](\"adr\"), \n",
        "    r.getAs[String](\"col\").toInt)\n",
        "}"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 20,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669853137358,
          "endTs" : 1669853137688
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// On transforme le dataframe caracteristique (Dataset[Row]) dans un DataSet caractDS (Dataset[Caracteristiques])\n",
        "val caractDS/*:Dataset[Caracteristiques]*/ = caracteristiques.filter(\n",
        "            x => {\n",
        "              try{\n",
        "                mapRow(x)\n",
        "                true\n",
        "              }catch {\n",
        "                case e: Exception => false\n",
        "              }\n",
        "            }).map{ mapRow }\n",
        "caracteristiques.show\n",
        "caractDS.show"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+------------+----+----+----+-----+---+---+-----+---+---+---+---+--------------------+---------------+----------------+\n",
            "|     Num_Acc|jour|mois|  an| hrmn|lum|dep|  com|agg|int|atm|col|                 adr|            lat|            long|\n",
            "+------------+----+----+----+-----+---+---+-----+---+---+---+---+--------------------+---------------+----------------+\n",
            "|202100000001|  30|  11|2021|07:32|  2| 30|30319|  1|  1|  1|  1|              CD 981|  44,0389580000|    4,3480220000|\n",
            "|202100000002|  25|  09|2021|14:20|  1| 51|51544|  1|  3|  1|  3|Aire de repos cro...|  49,2421290000|    4,5545460000|\n",
            "|202100000003|  15|  07|2021|07:55|  1| 85|85048|  2|  1|  7|  6|15 rue François N...|  46,9219500000|   -0,9644600000|\n",
            "|202100000004|  27|  03|2021|19:45|  5| 93|93005|  2|  2|  3|  6|      Route de Mitry|  48,9493634583|    2,5196639908|\n",
            "|202100000005|  25|  02|2021|07:20|  5| 76|76429|  2|  1|  1|  2|     PARIS. ROUTE DE|  49,4083800000|    1,1458100000|\n",
            "|202100000006|  23|  11|2021|11:10|  1| 68|68004|  2|  3|  1|  2|Rue Charles Edoua...|  47,6142390000|    7,2343360000|\n",
            "|202100000007|  13|  12|2021|19:10|  5| 38|38053|  2|  9|  1|  1|REPUBLIQUE (PLACE...|  45,5888000000|    5,2730500000|\n",
            "|202100000008|  21|  11|2021|16:30|  1|987|98715|  2|  1|  1|  3|     RT 1 - PK 5+500| -17,5845220000| -149,5685780000|\n",
            "|202100000009|  29|  12|2021|16:45|  2| 92|92048|  2|  2|  2|  3|REPUBLIQUE (RUE D...|  48,8065500000|    2,2358800000|\n",
            "|202100000010|  16|  10|2021|09:53|  1| 93|93008|  2|  1|  1|  3|VAILLANT COUTURIE...|  48,9075657758|    2,4547603726|\n",
            "|202100000011|  13|  10|2021|16:00|  1| 93|93008|  2|  2|  1|  3|      CHOUMERY (RUE)|  48,9074000000|    2,4568400000|\n",
            "|202100000012|  20|  10|2021|19:45|  3| 21|21173|  1|  1|  1|  1|                 D20|  47,0407010000|    4,8608280000|\n",
            "|202100000013|  18|  12|2021|01:15|  3|974|97418|  1|  1|  1|  2|         RN2 - PK 10| -20,9310800000|   55,5372190000|\n",
            "|202100000014|  17|  10|2021|15:24|  1| 92|92063|  2|  2|  1|  3|HOPITAL STELL (BO...|  48,8810767676|    2,1844232082|\n",
            "|202100000015|   2|  12|2021|13:10|  1| 51|51388|  1|  2|  1|  3|                 D19|  49,1330510000|    4,3370890000|\n",
            "|202100000016|  28|  12|2021|16:30|  1| 21|21349|  2|  1|  2|  6|    12 Route d Autun|  47,1944320000|    4,2713810000|\n",
            "|202100000017|  23|  10|2021|14:00|  1| 51|51362|  1|  1|  1|  3|                 A26|  49,2759855047|    3,9647179842|\n",
            "|202100000018|  13|  09|2021|13:00|  1| 14|14203|  1|  1|  1|  6|                 A13|  49,2321610000|   -0,0643750000|\n",
            "|202100000019|  17|  09|2021|20:10|  3| 73|73096|  1|  1|  1|  3|D201, route de la...|  45,5184960000|    6,0863610000|\n",
            "|202100000020|  24|  10|2021|13:15|  1| 91|91027|  2|  1|  1|  2|AV FRANCOIS MITTE...|  48,7042539233|    2,3720598221|\n",
            "+------------+----+----+----+-----+---+---+-----+---+---+---+---+--------------------+---------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------------+-------------+------------+--------------------+-------+\n",
            "|      NumAcc|     latitude|   longitude|                 adr|colType|\n",
            "+------------+-------------+------------+--------------------+-------+\n",
            "|202100000001|    44.038958|    4.348022|              CD 981|      1|\n",
            "|202100000002|    49.242129|    4.554546|Aire de repos cro...|      3|\n",
            "|202100000003|     46.92195|    -0.96446|15 rue François N...|      6|\n",
            "|202100000004|48.9493634583|2.5196639908|      Route de Mitry|      6|\n",
            "|202100000005|     49.40838|     1.14581|     PARIS. ROUTE DE|      2|\n",
            "|202100000006|    47.614239|    7.234336|Rue Charles Edoua...|      2|\n",
            "|202100000007|      45.5888|     5.27305|REPUBLIQUE (PLACE...|      1|\n",
            "|202100000008|   -17.584522| -149.568578|     RT 1 - PK 5+500|      3|\n",
            "|202100000009|     48.80655|     2.23588|REPUBLIQUE (RUE D...|      3|\n",
            "|202100000010|48.9075657758|2.4547603726|VAILLANT COUTURIE...|      3|\n",
            "|202100000011|      48.9074|     2.45684|      CHOUMERY (RUE)|      3|\n",
            "|202100000012|    47.040701|    4.860828|                 D20|      1|\n",
            "|202100000013|    -20.93108|   55.537219|         RN2 - PK 10|      2|\n",
            "|202100000014|48.8810767676|2.1844232082|HOPITAL STELL (BO...|      3|\n",
            "|202100000015|    49.133051|    4.337089|                 D19|      3|\n",
            "|202100000016|    47.194432|    4.271381|    12 Route d Autun|      6|\n",
            "|202100000017|49.2759855047|3.9647179842|                 A26|      3|\n",
            "|202100000018|    49.232161|   -0.064375|                 A13|      6|\n",
            "|202100000019|    45.518496|    6.086361|D201, route de la...|      3|\n",
            "|202100000020|48.7042539233|2.3720598221|AV FRANCOIS MITTE...|      2|\n",
            "+------------+-------------+------------+--------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 21,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669853167022,
          "endTs" : 1669853167103
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// On defnit une methode qui pour une Caracteristique retourne true si la Caracteristique decrit un accident proche d'un endroit particulier (lat:48.71 et long:2.24)\n",
        "def nearPlace(c:Caracteristiques): Boolean = {\n",
        "   ( Math.abs(c.latitude - 48.71)< 0.06 && Math.abs(c.longitude - 2.24) < 0.06)\n",
        "}\n",
        "nearPlace(Caracteristiques(\"test\",48.71,2.24,\" my home\", 0))// on test la methode en l'appliquant sur une Caracteristique\n"
      ],
      "outputs" : [
        {
          "execution_count" : 21,
          "data" : {
            "text/plain" : [
              "true"
            ]
          },
          "metadata" : {
            "name" : "Out",
            "type" : "Boolean"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 22,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669853180700,
          "endTs" : 1669853180928
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// Trouver un accident proche\n",
        "caractDS.filter(nearPlace _).show(10,false)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+------------+-------------+------------+--------------------------+-------+\n",
            "|NumAcc      |latitude     |longitude   |adr                       |colType|\n",
            "+------------+-------------+------------+--------------------------+-------+\n",
            "|202100000162|48.702077    |2.190553    |CHARLES DE GAULLE (RUE)   |3      |\n",
            "|202100000660|48.664593    |2.213681    |CD 35                     |2      |\n",
            "|202100001134|48.7121      |2.18348     |RN 118                    |5      |\n",
            "|202100001136|48.716137    |2.267079    |RD188 PROVINCE / A10 PARIS|7      |\n",
            "|202100001162|48.684958    |2.182663    |FERME (RUE DE LA)         |3      |\n",
            "|202100001163|48.70766     |2.2406      |HUIT MAI 1945 (AVENUE DU) |6      |\n",
            "|202100001251|48.7598784006|2.2696311721|N385                      |2      |\n",
            "|202100001346|48.750109    |2.203517    |RN 118                    |7      |\n",
            "|202100001347|48.72895     |2.29468     |RD 188                    |4      |\n",
            "|202100001431|48.710886    |2.288146    |AUTOROUTE A10             |7      |\n",
            "+------------+-------------+------------+--------------------------+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 23,
      "metadata" : {
        "language" : "viz"
      },
      "language" : "viz",
      "source" : [
        "{\"type\":\"table\",\"value\":\"Out\"}"
      ],
      "outputs" : [
        {
          "data" : {
            "text/html" : [
            ]
          },
          "output_type" : "display_data"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 24,
      "metadata" : {
        "language" : "viz"
      },
      "language" : "viz",
      "source" : [
        "{\"type\":\"plot\",\"value\":\"Out\",\"plotDefinition\":{\"value\":\"Out\",\"title\":\"Out\",\"forceZero\":true,\"plot\":{\"type\":\"bar\",\"x\":{\"field\":\"NumAcc\"},\"y\":{\"series\":[]},\"stacked\":true}}}"
      ],
      "outputs" : [
        {
          "data" : {
            "text/plain" : [
              "[Lnotebook0.Cell21$2$Caracteristiques;@7a07ec2c"
            ]
          },
          "output_type" : "display_data"
        }
      ]
    },
    {
      "cell_type" : "markdown",
      "execution_count" : 25,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "3.1 WordCount avec *Spark* et *Cassandra*"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 26,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669876324162,
          "endTs" : 1669876324207
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import com.datastax.spark.connector._\n",
        "\n",
        "val rdd = spark.sparkContext.cassandraTable(\"temperature\", \"temp1\")"
      ],
      "outputs" : [
        {
          "execution_count" : 26,
          "data" : {
            "application/json" : [
              {
                "pos" : {
                  "sourceId" : "Cell26",
                  "start" : 49,
                  "end" : 82,
                  "point" : 68
                },
                "msg" : "value cassandraTable is not a member of org.apache.spark.SparkContext",
                "severity" : 2
              }
            ],
            "text/plain" : [
              "Error: value cassandraTable is not a member of org.apache.spark.SparkContext (49)"
            ]
          },
          "metadata" : {
            "rel" : "compiler_errors"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 27,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1669874971838,
          "endTs" : 1669874972093
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
      ],
      "outputs" : [
      ]
    }
  ]
}